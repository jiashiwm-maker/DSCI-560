{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1769881414163,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "gVn8viF6JeiL",
    "outputId": "0494a9ed-0478-4f05-9b08-23f77de1d237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
      "Cuda compilation tools, release 12.5, V12.5.82\n",
      "Build cuda_12.5.r12.5/compiler.34385749_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4862,
     "status": "ok",
     "timestamp": 1769881430467,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "LRuU65jtJzIK",
    "outputId": "a4ec8f4e-ba6a-4572-955b-5522e852f42b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvcc4jupyter\n",
      "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: nvcc4jupyter\n",
      "Successfully installed nvcc4jupyter-1.2.1\n",
      "Detected platform \"Colab\". Running its setup...\n",
      "Source files will be saved in \"/tmp/tmp5oojonum\".\n"
     ]
    }
   ],
   "source": [
    "!pip install nvcc4jupyter\n",
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1769882498885,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "4G3-IZRQJ3VB",
    "outputId": "23b5fc7d-e6c6-4890-af9d-39bc02147770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing matrix_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_gpu.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "\n",
    "__global__ void matrixMultiplyGPU(float *A, float *B, float *C, int N) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (row < N && col < N) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < N; k++) {\n",
    "            sum += A[row * N + k] * B[k * N + col];\n",
    "        }\n",
    "        C[row * N + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int M = (argc > 1) ? atoi(argv[1]) : 1024; // allow matrix size as input\n",
    "    for (int i = 1; i <= M / 512; i *= 2) {\n",
    "        int N = 512 * i;\n",
    "        size_t size = N * N * sizeof(float);\n",
    "\n",
    "        float *A;\n",
    "        cudaMallocManaged(&A, size);\n",
    "        float *B;\n",
    "        cudaMallocManaged(&B, size);\n",
    "        float *C;\n",
    "        cudaMallocManaged(&C, size);\n",
    "\n",
    "        for (int i = 0; i < N * N; i++) {\n",
    "            A[i] = rand() % 100 / 100.0f;\n",
    "            B[i] = rand() % 100 / 100.0f;\n",
    "        }\n",
    "\n",
    "        dim3 threadsPerBlock(16, 16);\n",
    "        dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                           (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "\n",
    "        clock_t start = clock();\n",
    "        matrixMultiplyGPU<<<blocksPerGrid, threadsPerBlock>>>(A, B, C, N);\n",
    "        cudaDeviceSynchronize();\n",
    "        clock_t end = clock();\n",
    "\n",
    "        double elapsed = (double)(end - start) / CLOCKS_PER_SEC;\n",
    "        printf(\"GPU execution time (N=%d): %f seconds\\n\", N, elapsed);\n",
    "\n",
    "        cudaFree(A); cudaFree(B); cudaFree(C);\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZE8wiW5MZPy"
   },
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 matrix_gpu.cu -o matrix_gpu_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1769882542827,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "2EYSUfjfOC6K",
    "outputId": "353dcde3-e91c-4b08-edaa-f76a3ac826e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU execution time (N=512): 0.002405 seconds\n",
      "GPU execution time (N=1024): 0.012200 seconds\n",
      "GPU execution time (N=2048): 0.088387 seconds\n"
     ]
    }
   ],
   "source": [
    "!./matrix_gpu_run 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1769883281438,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "Jm2TBftBOppR",
    "outputId": "66353f5a-aef7-49de-e487-2621cf90f8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_gpu_tiled.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_gpu_tiled.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "\n",
    "#define TILE_WIDTH 16\n",
    "\n",
    "__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n",
    "    __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n",
    "    __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n",
    "\n",
    "    int bx = blockIdx.x; int by = blockIdx.y;\n",
    "    int tx = threadIdx.x; int ty = threadIdx.y;\n",
    "\n",
    "    int Row = by * TILE_WIDTH + ty;\n",
    "    int Col = bx * TILE_WIDTH + tx;\n",
    "\n",
    "    float Pvalue = 0.0;\n",
    "    for (int m = 0; m < (N + TILE_WIDTH - 1) / TILE_WIDTH; ++m) {\n",
    "        if (Row < N && (m*TILE_WIDTH+tx) < N)\n",
    "            ds_A[ty][tx] = A[Row * N + m * TILE_WIDTH + tx];\n",
    "        else\n",
    "            ds_A[ty][tx] = 0.0f;\n",
    "\n",
    "        if (Col < N && (m*TILE_WIDTH+ty) < N)\n",
    "            ds_B[ty][tx] = B[(m*TILE_WIDTH + ty) * N + Col];\n",
    "        else\n",
    "            ds_B[ty][tx] = 0.0f;\n",
    "\n",
    "        __syncthreads();\n",
    "\n",
    "        for (int k = 0; k < TILE_WIDTH; ++k)\n",
    "            Pvalue += ds_A[ty][k] * ds_B[k][tx];\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (Row < N && Col < N)\n",
    "        C[Row * N + Col] = Pvalue;\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int M = (argc > 1) ? atoi(argv[1]) : 1024; // allow matrix size as input\n",
    "    for (int i = 1; i <= M / 512; i *= 2) {\n",
    "        int N = 512 * i;\n",
    "        size_t size = N * N * sizeof(float);\n",
    "\n",
    "        float *A;\n",
    "        cudaMallocManaged(&A, size);\n",
    "        float *B;\n",
    "        cudaMallocManaged(&B, size);\n",
    "        float *C;\n",
    "        cudaMallocManaged(&C, size);\n",
    "\n",
    "        for (int i = 0; i < N * N; i++) {\n",
    "            A[i] = rand() % 100 / 100.0f;\n",
    "            B[i] = rand() % 100 / 100.0f;\n",
    "        }\n",
    "\n",
    "        dim3 threadsPerBlock(16, 16);\n",
    "        dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                           (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "\n",
    "        clock_t start = clock();\n",
    "        matrixMultiplyTiled<<<blocksPerGrid, threadsPerBlock>>>(A, B, C, N);\n",
    "        cudaDeviceSynchronize();\n",
    "        clock_t end = clock();\n",
    "\n",
    "        double elapsed = (double)(end - start) / CLOCKS_PER_SEC;\n",
    "        printf(\"GPU execution time (N=%d): %f seconds\\n\", N, elapsed);\n",
    "\n",
    "        cudaFree(A); cudaFree(B); cudaFree(C);\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCZ3lixWPCCi"
   },
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 matrix_gpu_tiled.cu -o matrix_gpu_tiled_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1769882848944,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "QiBROnS_PN1c",
    "outputId": "32d29412-84c7-4551-d999-2cc01c3c0660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU execution time (N=512): 0.002101 seconds\n",
      "GPU execution time (N=1024): 0.009680 seconds\n",
      "GPU execution time (N=2048): 0.060095 seconds\n"
     ]
    }
   ],
   "source": [
    "!./matrix_gpu_tiled_run 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1769883364999,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "JLTnk6e9Pm9l",
    "outputId": "07084941-8ac5-4b3d-ffc4-a80d2a415baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_gpu_cublas.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_gpu_cublas.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <cublas_v2.h>\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int M = (argc > 1) ? atoi(argv[1]) : 1024; // allow matrix size as input\n",
    "    cublasHandle_t handle;\n",
    "    cublasCreate(&handle);\n",
    "\n",
    "    const float alpha = 1.0f;\n",
    "    const float beta = 0.0f;\n",
    "\n",
    "    for (int i = 1; i <= M / 512; i *= 2) {\n",
    "        int N = 512 * i;\n",
    "        size_t size = N * N * sizeof(float);\n",
    "\n",
    "        float *A;\n",
    "        cudaMallocManaged(&A, size);\n",
    "        float *B;\n",
    "        cudaMallocManaged(&B, size);\n",
    "        float *C;\n",
    "        cudaMallocManaged(&C, size);\n",
    "\n",
    "        for (int i = 0; i < N * N; i++) {\n",
    "            A[i] = rand() % 100 / 100.0f;\n",
    "            B[i] = rand() % 100 / 100.0f;\n",
    "        }\n",
    "\n",
    "        dim3 threadsPerBlock(16, 16);\n",
    "        dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                           (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "\n",
    "        clock_t start = clock();\n",
    "        cublasSgemm(handle,\n",
    "              CUBLAS_OP_N,\n",
    "              CUBLAS_OP_N,\n",
    "              N, N, N,\n",
    "              &alpha,\n",
    "              B, N,\n",
    "              A, N,\n",
    "              &beta,\n",
    "              C, N);\n",
    "        cudaDeviceSynchronize();\n",
    "        clock_t end = clock();\n",
    "\n",
    "        double elapsed = (double)(end - start) / CLOCKS_PER_SEC;\n",
    "        printf(\"GPU execution time (N=%d): %f seconds\\n\", N, elapsed);\n",
    "\n",
    "        cudaFree(A); cudaFree(B); cudaFree(C);\n",
    "    }\n",
    "    cublasDestroy(handle);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kot9V6nORBC-"
   },
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 matrix_gpu_cublas.cu -o matrix_gpu_cublas_run -lcublas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1317,
     "status": "ok",
     "timestamp": 1769883466647,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "P-srv85PRjuy",
    "outputId": "8376fdb7-27bd-4f4c-ff56-8027ec4bfe32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU execution time (N=512): 0.009214 seconds\n",
      "GPU execution time (N=1024): 0.003726 seconds\n",
      "GPU execution time (N=2048): 0.016172 seconds\n"
     ]
    }
   ],
   "source": [
    "!./matrix_gpu_cublas_run 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1769884492232,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "rs787O22SoRJ",
    "outputId": "52cdcc65-9ef1-47c8-94e7-0e7815be059b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing matrix_lib.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_lib.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "#define TILE_WIDTH 16\n",
    "\n",
    "__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n",
    "    __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n",
    "    __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n",
    "\n",
    "    int bx = blockIdx.x; int by = blockIdx.y;\n",
    "    int tx = threadIdx.x; int ty = threadIdx.y;\n",
    "\n",
    "    int Row = by * TILE_WIDTH + ty;\n",
    "    int Col = bx * TILE_WIDTH + tx;\n",
    "\n",
    "    float Pvalue = 0.0;\n",
    "    for (int m = 0; m < (N + TILE_WIDTH - 1) / TILE_WIDTH; ++m) {\n",
    "        if (Row < N && (m*TILE_WIDTH+tx) < N)\n",
    "            ds_A[ty][tx] = A[Row * N + m * TILE_WIDTH + tx];\n",
    "        else\n",
    "            ds_A[ty][tx] = 0.0f;\n",
    "\n",
    "        if (Col < N && (m*TILE_WIDTH+ty) < N)\n",
    "            ds_B[ty][tx] = B[(m*TILE_WIDTH + ty) * N + Col];\n",
    "        else\n",
    "            ds_B[ty][tx] = 0.0f;\n",
    "\n",
    "        __syncthreads();\n",
    "\n",
    "        for (int k = 0; k < TILE_WIDTH; ++k)\n",
    "            Pvalue += ds_A[ty][k] * ds_B[k][tx];\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (Row < N && Col < N)\n",
    "        C[Row * N + Col] = Pvalue;\n",
    "}\n",
    "\n",
    "// Exposed C function for Python\n",
    "extern \"C\" void gpu_matrix_multiply(float *h_A, float *h_B, float *h_C, int\n",
    "N) {\n",
    "    size_t size = N * N * sizeof(float);\n",
    "    float *d_A, *d_B, *d_C;\n",
    "\n",
    "    cudaMalloc((void**)&d_A, size);\n",
    "    cudaMalloc((void**)&d_B, size);\n",
    "    cudaMalloc((void**)&d_C, size);\n",
    "\n",
    "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimBlock(TILE_WIDTH, TILE_WIDTH);\n",
    "    dim3 dimGrid((N + TILE_WIDTH - 1) / TILE_WIDTH, (N + TILE_WIDTH - 1) /\n",
    "TILE_WIDTH);\n",
    "\n",
    "    matrixMultiplyTiled<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5MWsGzAVi8c"
   },
   "outputs": [],
   "source": [
    "!nvcc -Xcompiler -fPIC -shared matrix_lib.cu -o libmatrix.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1769884535059,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "VrFlYkxwVq3R",
    "outputId": "343e55af-211c-45ec-e3a4-ca697352426e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python call to CUDA library completed in 0.1164 seconds\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load shared library\n",
    "lib = ctypes.cdll.LoadLibrary(\"./libmatrix.so\")\n",
    "\n",
    "# Define argument types\n",
    "lib.gpu_matrix_multiply.argtypes = [\n",
    "np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "ctypes.c_int\n",
    "]\n",
    "N = 1024\n",
    "A = np.random.rand(N, N).astype(np.float32)\n",
    "B = np.random.rand(N, N).astype(np.float32)\n",
    "C = np.zeros((N, N), dtype=np.float32)\n",
    "start = time.time()\n",
    "lib.gpu_matrix_multiply(A.ravel(), B.ravel(), C.ravel(), N)\n",
    "end = time.time()\n",
    "print(f\"Python call to CUDA library completed in {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1769903582954,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "cMb60ftydmwK",
    "outputId": "14589134-8161-4e20-9d09-ebf65c6cd378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "project_path = '/content/drive/MyDrive/Colab Notebooks/scripts'\n",
    "os.makedirs(project_path, exist_ok=True)\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1769903999615,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "wEQhbATbf5r4",
    "outputId": "8468dff6-0c39-4ef4-8018-5c383decddb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"test_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1769904014624,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "WggEOetrfvtB",
    "outputId": "d93a129a-e0e4-4781-e57d-27e51dccc4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting convolution_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile convolution_gpu.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void convolutionGPU(unsigned int *input, unsigned int *output, float *kernel, int M, int N) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int offset = N / 2;\n",
    "\n",
    "    if (row < M && col < M) {\n",
    "        float sum = 0.0f;\n",
    "        for (int ki = 0; ki < N; ki++) {\n",
    "            for (int kj = 0; kj < N; kj++) {\n",
    "                int ii = row + ki - offset;\n",
    "                int jj = col + kj - offset;\n",
    "                if (ii >= 0 && ii < M && jj >= 0 && jj < M) {\n",
    "                    sum += input[ii * M + jj] * kernel[ki * N + kj];\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        if (sum < 0.0f) sum = 0.0f;\n",
    "        if (sum > 255.0f) sum = 255.0f;\n",
    "        output[row * M + col] = (unsigned int)sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "unsigned int* readMatrixManaged(const char *filename, int *M) {\n",
    "    FILE *fp = fopen(filename, \"r\");\n",
    "    if (!fp) return NULL;\n",
    "    int cols;\n",
    "    if (fscanf(fp, \"%d %d\", M, &cols) != 2) {\n",
    "        fclose(fp);\n",
    "        return NULL;\n",
    "    }\n",
    "    unsigned int *data;\n",
    "    cudaMallocManaged(&data, *M * *M * sizeof(unsigned int));\n",
    "    for (int i = 0; i < *M * *M; i++) {\n",
    "        fscanf(fp, \"%u\", &data[i]);\n",
    "    }\n",
    "    fclose(fp);\n",
    "    return data;\n",
    "}\n",
    "\n",
    "void saveMatrix(const char *filename, unsigned int *data, int M) {\n",
    "    FILE *fp = fopen(filename, \"w\");\n",
    "    if (!fp) return;\n",
    "    fprintf(fp, \"%d %d\\n\", M, M);\n",
    "    for (int i = 0; i < M * M; i++) {\n",
    "        fprintf(fp, \"%u \", data[i]);\n",
    "        if ((i + 1) % M == 0) fprintf(fp, \"\\n\");\n",
    "    }\n",
    "    fclose(fp);\n",
    "}\n",
    "\n",
    "float* generateFilterManaged(int N) {\n",
    "    float *filter;\n",
    "    cudaMallocManaged(&filter, N * N * sizeof(float));\n",
    "    if (N == 3) {\n",
    "        float laplacian[9] = {0, -1, 0, -1, 4, -1, 0, -1, 0};\n",
    "        for(int i=0; i<9; i++) filter[i] = laplacian[i];\n",
    "    } else {\n",
    "        float val = 1.0f / (N * N);\n",
    "        for (int i = 0; i < N * N; i++) {\n",
    "            filter[i] = val;\n",
    "        }\n",
    "    }\n",
    "    return filter;\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    const char *filenames[] = {\"test_1.txt\", \"test_2.txt\", \"test_3.txt\"};\n",
    "    int filter_sizes[] = {3, 5, 7};\n",
    "    int num_images = 3;\n",
    "    int num_filters = 3;\n",
    "\n",
    "    for (int i = 0; i < num_images; i++) {\n",
    "        const char *input_path = filenames[i];\n",
    "\n",
    "        int M;\n",
    "        unsigned int *input = readMatrixManaged(input_path, &M);\n",
    "        if (!input) {\n",
    "            printf(\"Failed to read file: %s\\n\", input_path);\n",
    "            continue;\n",
    "        }\n",
    "\n",
    "        unsigned int *output;\n",
    "        cudaMallocManaged(&output, M * M * sizeof(unsigned int));\n",
    "\n",
    "        for (int j = 0; j < num_filters; j++) {\n",
    "            int N = filter_sizes[j];\n",
    "            float *kernel = generateFilterManaged(N);\n",
    "\n",
    "            dim3 threadsPerBlock(16, 16);\n",
    "            dim3 blocksPerGrid((M + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                               (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "\n",
    "            clock_t start = clock();\n",
    "            convolutionGPU<<<blocksPerGrid, threadsPerBlock>>>(input, output, kernel, M, N);\n",
    "            cudaDeviceSynchronize();\n",
    "            clock_t end = clock();\n",
    "\n",
    "            double elapsed = (double)(end - start) / CLOCKS_PER_SEC;\n",
    "            printf(\"Image: %s (MxM=%dx%d), Filter: %dx%d, Time: %f s\\n\",\n",
    "                   filenames[i], M, M, N, N, elapsed);\n",
    "\n",
    "            char output_path[64];\n",
    "            sprintf(output_path, \"result_%d_%dx%d.txt\", M, N, N);\n",
    "            saveMatrix(output_path, output, M);\n",
    "\n",
    "            cudaFree(kernel);\n",
    "        }\n",
    "\n",
    "        cudaFree(input);\n",
    "        cudaFree(output);\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1769904018345,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "2IzIiBbedCEO"
   },
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_75 convolution_gpu.cu -o convolution_gpu_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4321,
     "status": "ok",
     "timestamp": 1769904025422,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "AeQcrG80dJPU",
    "outputId": "7e017a9b-5cd1-4515-f69f-04014ef81548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: test_1.txt (MxM=2048x2048), Filter: 3x3, Time: 0.008173 s\n",
      "Image: test_1.txt (MxM=2048x2048), Filter: 5x5, Time: 0.006555 s\n",
      "Image: test_1.txt (MxM=2048x2048), Filter: 7x7, Time: 0.006922 s\n",
      "Image: test_2.txt (MxM=1024x1024), Filter: 3x3, Time: 0.004860 s\n",
      "Image: test_2.txt (MxM=1024x1024), Filter: 5x5, Time: 0.003811 s\n",
      "Image: test_2.txt (MxM=1024x1024), Filter: 7x7, Time: 0.001347 s\n",
      "Image: test_3.txt (MxM=512x512), Filter: 3x3, Time: 0.000082 s\n",
      "Image: test_3.txt (MxM=512x512), Filter: 5x5, Time: 0.000058 s\n",
      "Image: test_3.txt (MxM=512x512), Filter: 7x7, Time: 0.000635 s\n"
     ]
    }
   ],
   "source": [
    "!./convolution_gpu_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1769904475408,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "D7pvgbPLgMxr",
    "outputId": "5f7cd974-38e9-4577-e3dd-5d63d9f1c2a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing convolution_lib.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile convolution_lib.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void convolutionGPU(unsigned int *input, unsigned int *output, float *kernel, int M, int N) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int offset = N / 2;\n",
    "\n",
    "    if (row < M && col < M) {\n",
    "        float sum = 0.0f;\n",
    "        for (int ki = 0; ki < N; ki++) {\n",
    "            for (int kj = 0; kj < N; kj++) {\n",
    "                int ii = row + ki - offset;\n",
    "                int jj = col + kj - offset;\n",
    "                if (ii >= 0 && ii < M && jj >= 0 && jj < M) {\n",
    "                    sum += input[ii * M + jj] * kernel[ki * N + kj];\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        if (sum < 0.0f) sum = 0.0f;\n",
    "        if (sum > 255.0f) sum = 255.0f;\n",
    "        output[row * M + col] = (unsigned int)sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "extern \"C\" void gpu_convolution_wrapper(unsigned int *h_input, unsigned int *h_output, float *h_kernel, int M, int N) {\n",
    "    unsigned int *d_input, *d_output;\n",
    "    float *d_kernel;\n",
    "    size_t img_size = M * M * sizeof(unsigned int);\n",
    "    size_t kern_size = N * N * sizeof(float);\n",
    "\n",
    "    cudaMalloc((void**)&d_input, img_size);\n",
    "    cudaMalloc((void**)&d_output, img_size);\n",
    "    cudaMalloc((void**)&d_kernel, kern_size);\n",
    "\n",
    "    cudaMemcpy(d_input, h_input, img_size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_kernel, h_kernel, kern_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 threadsPerBlock(16, 16);\n",
    "    dim3 blocksPerGrid((M + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                       (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "\n",
    "    convolutionGPU<<<blocksPerGrid, threadsPerBlock>>>(d_input, d_output, d_kernel, M, N);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    cudaMemcpy(h_output, d_output, img_size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    cudaFree(d_kernel);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1769904483618,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "YR1g-k5Uhxcf"
   },
   "outputs": [],
   "source": [
    "!nvcc -Xcompiler -fPIC -shared -o convolution_lib.so convolution_lib.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4159,
     "status": "ok",
     "timestamp": 1769904522991,
     "user": {
      "displayName": "Dr Duke",
      "userId": "13759096210497998176"
     },
     "user_tz": 480
    },
    "id": "irN2RX9RhzVX",
    "outputId": "cd18f1e4-c9e4-4908-bc55-30af5aac7c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: test_1.txt (MxM=2048x2048), Filter: 3x3, Time: 0.166284 s\n",
      "Image: test_1.txt (MxM=2048x2048), Filter: 5x5, Time: 0.011030 s\n",
      "Image: test_1.txt (MxM=2048x2048), Filter: 7x7, Time: 0.012252 s\n",
      "Image: test_2.txt (MxM=1024x1024), Filter: 3x3, Time: 0.003047 s\n",
      "Image: test_2.txt (MxM=1024x1024), Filter: 5x5, Time: 0.004043 s\n",
      "Image: test_2.txt (MxM=1024x1024), Filter: 7x7, Time: 0.004118 s\n",
      "Image: test_3.txt (MxM=512x512), Filter: 3x3, Time: 0.001529 s\n",
      "Image: test_3.txt (MxM=512x512), Filter: 5x5, Time: 0.001608 s\n",
      "Image: test_3.txt (MxM=512x512), Filter: 7x7, Time: 0.001569 s\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "def get_kernel(N):\n",
    "    if N == 3:\n",
    "        return np.array([0, -1, 0, -1, 4, -1, 0, -1, 0], dtype=np.float32)\n",
    "    else:\n",
    "        return np.full(N * N, 1.0 / (N * N), dtype=np.float32)\n",
    "\n",
    "lib = ctypes.CDLL('./convolution_lib.so')\n",
    "lib.gpu_convolution_wrapper.argtypes = [\n",
    "    np.ctypeslib.ndpointer(dtype=np.uint32, ndim=1),\n",
    "    np.ctypeslib.ndpointer(dtype=np.uint32, ndim=1),\n",
    "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1),\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_int\n",
    "]\n",
    "\n",
    "filenames = [\"test_1.txt\", \"test_2.txt\", \"test_3.txt\"]\n",
    "filter_sizes = [3, 5, 7]\n",
    "\n",
    "for fname in filenames:\n",
    "    if not os.path.exists(fname):\n",
    "        print(f\"File not found: {fname}\")\n",
    "        continue\n",
    "\n",
    "    with open(fname, 'r') as f:\n",
    "        header = f.readline().split()\n",
    "        M = int(header[0])\n",
    "\n",
    "    h_input = np.loadtxt(fname, skiprows=1, dtype=np.uint32).flatten()\n",
    "    h_output = np.zeros_like(h_input)\n",
    "\n",
    "    for N in filter_sizes:\n",
    "        h_kernel = get_kernel(N)\n",
    "\n",
    "        start_time = time.time()\n",
    "        lib.gpu_convolution_wrapper(h_input, h_output, h_kernel, M, N)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Image: {fname} (MxM={M}x{M}), Filter: {N}x{N}, Time: {end_time - start_time:.6f} s\")\n",
    "\n",
    "        out_name = f\"result_{M}_{N}x{N}.txt\"\n",
    "        np.savetxt(out_name, h_output.reshape(M, M), fmt='%u', header=f\"{M} {M}\", comments='')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMlAeMgjMAk4EhcFgdN6PLW",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
