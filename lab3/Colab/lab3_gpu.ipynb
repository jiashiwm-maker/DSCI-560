{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMlAeMgjMAk4EhcFgdN6PLW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVn8viF6JeiL","executionInfo":{"status":"ok","timestamp":1769881414163,"user_tz":480,"elapsed":108,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"0494a9ed-0478-4f05-9b08-23f77de1d237"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Jun__6_02:18:23_PDT_2024\n","Cuda compilation tools, release 12.5, V12.5.82\n","Build cuda_12.5.r12.5/compiler.34385749_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","source":["!pip install nvcc4jupyter\n","%load_ext nvcc4jupyter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRuU65jtJzIK","executionInfo":{"status":"ok","timestamp":1769881430467,"user_tz":480,"elapsed":4862,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"a4ec8f4e-ba6a-4572-955b-5522e852f42b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nvcc4jupyter\n","  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n","Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.1\n","Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmp5oojonum\".\n"]}]},{"cell_type":"code","source":["%%writefile matrix_gpu.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <time.h>\n","\n","__global__ void matrixMultiplyGPU(float *A, float *B, float *C, int N) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (row < N && col < N) {\n","        float sum = 0.0f;\n","        for (int k = 0; k < N; k++) {\n","            sum += A[row * N + k] * B[k * N + col];\n","        }\n","        C[row * N + col] = sum;\n","    }\n","}\n","\n","int main(int argc, char **argv) {\n","    int M = (argc > 1) ? atoi(argv[1]) : 1024; // allow matrix size as input\n","    for (int i = 1; i <= M / 512; i *= 2) {\n","        int N = 512 * i;\n","        size_t size = N * N * sizeof(float);\n","\n","        float *A;\n","        cudaMallocManaged(&A, size);\n","        float *B;\n","        cudaMallocManaged(&B, size);\n","        float *C;\n","        cudaMallocManaged(&C, size);\n","\n","        for (int i = 0; i < N * N; i++) {\n","            A[i] = rand() % 100 / 100.0f;\n","            B[i] = rand() % 100 / 100.0f;\n","        }\n","\n","        dim3 threadsPerBlock(16, 16);\n","        dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n","                           (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n","\n","        clock_t start = clock();\n","        matrixMultiplyGPU<<<blocksPerGrid, threadsPerBlock>>>(A, B, C, N);\n","        cudaDeviceSynchronize();\n","        clock_t end = clock();\n","\n","        double elapsed = (double)(end - start) / CLOCKS_PER_SEC;\n","        printf(\"GPU execution time (N=%d): %f seconds\\n\", N, elapsed);\n","\n","        cudaFree(A); cudaFree(B); cudaFree(C);\n","    }\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4G3-IZRQJ3VB","executionInfo":{"status":"ok","timestamp":1769882498885,"user_tz":480,"elapsed":10,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"23b5fc7d-e6c6-4890-af9d-39bc02147770"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing matrix_gpu.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 matrix_gpu.cu -o matrix_gpu_run"],"metadata":{"id":"YZE8wiW5MZPy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./matrix_gpu_run 2048"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EYSUfjfOC6K","executionInfo":{"status":"ok","timestamp":1769882542827,"user_tz":480,"elapsed":511,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"353dcde3-e91c-4b08-edaa-f76a3ac826e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU execution time (N=512): 0.002405 seconds\n","GPU execution time (N=1024): 0.012200 seconds\n","GPU execution time (N=2048): 0.088387 seconds\n"]}]},{"cell_type":"code","source":["%%writefile matrix_gpu_tiled.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <time.h>\n","\n","#define TILE_WIDTH 16\n","\n","__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n","    __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n","    __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n","\n","    int bx = blockIdx.x; int by = blockIdx.y;\n","    int tx = threadIdx.x; int ty = threadIdx.y;\n","\n","    int Row = by * TILE_WIDTH + ty;\n","    int Col = bx * TILE_WIDTH + tx;\n","\n","    float Pvalue = 0.0;\n","    for (int m = 0; m < (N + TILE_WIDTH - 1) / TILE_WIDTH; ++m) {\n","        if (Row < N && (m*TILE_WIDTH+tx) < N)\n","            ds_A[ty][tx] = A[Row * N + m * TILE_WIDTH + tx];\n","        else\n","            ds_A[ty][tx] = 0.0f;\n","\n","        if (Col < N && (m*TILE_WIDTH+ty) < N)\n","            ds_B[ty][tx] = B[(m*TILE_WIDTH + ty) * N + Col];\n","        else\n","            ds_B[ty][tx] = 0.0f;\n","\n","        __syncthreads();\n","\n","        for (int k = 0; k < TILE_WIDTH; ++k)\n","            Pvalue += ds_A[ty][k] * ds_B[k][tx];\n","        __syncthreads();\n","    }\n","\n","    if (Row < N && Col < N)\n","        C[Row * N + Col] = Pvalue;\n","}\n","\n","int main(int argc, char **argv) {\n","    int M = (argc > 1) ? atoi(argv[1]) : 1024; // allow matrix size as input\n","    for (int i = 1; i <= M / 512; i *= 2) {\n","        int N = 512 * i;\n","        size_t size = N * N * sizeof(float);\n","\n","        float *A;\n","        cudaMallocManaged(&A, size);\n","        float *B;\n","        cudaMallocManaged(&B, size);\n","        float *C;\n","        cudaMallocManaged(&C, size);\n","\n","        for (int i = 0; i < N * N; i++) {\n","            A[i] = rand() % 100 / 100.0f;\n","            B[i] = rand() % 100 / 100.0f;\n","        }\n","\n","        dim3 threadsPerBlock(16, 16);\n","        dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n","                           (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n","\n","        clock_t start = clock();\n","        matrixMultiplyTiled<<<blocksPerGrid, threadsPerBlock>>>(A, B, C, N);\n","        cudaDeviceSynchronize();\n","        clock_t end = clock();\n","\n","        double elapsed = (double)(end - start) / CLOCKS_PER_SEC;\n","        printf(\"GPU execution time (N=%d): %f seconds\\n\", N, elapsed);\n","\n","        cudaFree(A); cudaFree(B); cudaFree(C);\n","    }\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jm2TBftBOppR","executionInfo":{"status":"ok","timestamp":1769883281438,"user_tz":480,"elapsed":7,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"66353f5a-aef7-49de-e487-2621cf90f8d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting matrix_gpu_tiled.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 matrix_gpu_tiled.cu -o matrix_gpu_tiled_run"],"metadata":{"id":"QCZ3lixWPCCi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./matrix_gpu_tiled_run 2048"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QiBROnS_PN1c","executionInfo":{"status":"ok","timestamp":1769882848944,"user_tz":480,"elapsed":506,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"32d29412-84c7-4551-d999-2cc01c3c0660"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU execution time (N=512): 0.002101 seconds\n","GPU execution time (N=1024): 0.009680 seconds\n","GPU execution time (N=2048): 0.060095 seconds\n"]}]},{"cell_type":"code","source":["%%writefile matrix_gpu_cublas.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <time.h>\n","#include <cublas_v2.h>\n","\n","int main(int argc, char **argv) {\n","    int M = (argc > 1) ? atoi(argv[1]) : 1024; // allow matrix size as input\n","    cublasHandle_t handle;\n","    cublasCreate(&handle);\n","\n","    const float alpha = 1.0f;\n","    const float beta = 0.0f;\n","\n","    for (int i = 1; i <= M / 512; i *= 2) {\n","        int N = 512 * i;\n","        size_t size = N * N * sizeof(float);\n","\n","        float *A;\n","        cudaMallocManaged(&A, size);\n","        float *B;\n","        cudaMallocManaged(&B, size);\n","        float *C;\n","        cudaMallocManaged(&C, size);\n","\n","        for (int i = 0; i < N * N; i++) {\n","            A[i] = rand() % 100 / 100.0f;\n","            B[i] = rand() % 100 / 100.0f;\n","        }\n","\n","        dim3 threadsPerBlock(16, 16);\n","        dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n","                           (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n","\n","        clock_t start = clock();\n","        cublasSgemm(handle,\n","              CUBLAS_OP_N,\n","              CUBLAS_OP_N,\n","              N, N, N,\n","              &alpha,\n","              B, N,\n","              A, N,\n","              &beta,\n","              C, N);\n","        cudaDeviceSynchronize();\n","        clock_t end = clock();\n","\n","        double elapsed = (double)(end - start) / CLOCKS_PER_SEC;\n","        printf(\"GPU execution time (N=%d): %f seconds\\n\", N, elapsed);\n","\n","        cudaFree(A); cudaFree(B); cudaFree(C);\n","    }\n","    cublasDestroy(handle);\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JLTnk6e9Pm9l","executionInfo":{"status":"ok","timestamp":1769883364999,"user_tz":480,"elapsed":48,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"07084941-8ac5-4b3d-ffc4-a80d2a415baa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting matrix_gpu_cublas.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 matrix_gpu_cublas.cu -o matrix_gpu_cublas_run -lcublas"],"metadata":{"id":"kot9V6nORBC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./matrix_gpu_cublas_run 2048"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-srv85PRjuy","executionInfo":{"status":"ok","timestamp":1769883466647,"user_tz":480,"elapsed":1317,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"8376fdb7-27bd-4f4c-ff56-8027ec4bfe32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU execution time (N=512): 0.009214 seconds\n","GPU execution time (N=1024): 0.003726 seconds\n","GPU execution time (N=2048): 0.016172 seconds\n"]}]},{"cell_type":"code","source":["%%writefile matrix_lib.cu\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","\n","#define TILE_WIDTH 16\n","\n","__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n","    __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n","    __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n","\n","    int bx = blockIdx.x; int by = blockIdx.y;\n","    int tx = threadIdx.x; int ty = threadIdx.y;\n","\n","    int Row = by * TILE_WIDTH + ty;\n","    int Col = bx * TILE_WIDTH + tx;\n","\n","    float Pvalue = 0.0;\n","    for (int m = 0; m < (N + TILE_WIDTH - 1) / TILE_WIDTH; ++m) {\n","        if (Row < N && (m*TILE_WIDTH+tx) < N)\n","            ds_A[ty][tx] = A[Row * N + m * TILE_WIDTH + tx];\n","        else\n","            ds_A[ty][tx] = 0.0f;\n","\n","        if (Col < N && (m*TILE_WIDTH+ty) < N)\n","            ds_B[ty][tx] = B[(m*TILE_WIDTH + ty) * N + Col];\n","        else\n","            ds_B[ty][tx] = 0.0f;\n","\n","        __syncthreads();\n","\n","        for (int k = 0; k < TILE_WIDTH; ++k)\n","            Pvalue += ds_A[ty][k] * ds_B[k][tx];\n","        __syncthreads();\n","    }\n","\n","    if (Row < N && Col < N)\n","        C[Row * N + Col] = Pvalue;\n","}\n","\n","// Exposed C function for Python\n","extern \"C\" void gpu_matrix_multiply(float *h_A, float *h_B, float *h_C, int\n","N) {\n","    size_t size = N * N * sizeof(float);\n","    float *d_A, *d_B, *d_C;\n","\n","    cudaMalloc((void**)&d_A, size);\n","    cudaMalloc((void**)&d_B, size);\n","    cudaMalloc((void**)&d_C, size);\n","\n","    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","    dim3 dimBlock(TILE_WIDTH, TILE_WIDTH);\n","    dim3 dimGrid((N + TILE_WIDTH - 1) / TILE_WIDTH, (N + TILE_WIDTH - 1) /\n","TILE_WIDTH);\n","\n","    matrixMultiplyTiled<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n","    cudaDeviceSynchronize();\n","\n","    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n","\n","    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rs787O22SoRJ","executionInfo":{"status":"ok","timestamp":1769884492232,"user_tz":480,"elapsed":8,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"52cdcc65-9ef1-47c8-94e7-0e7815be059b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing matrix_lib.cu\n"]}]},{"cell_type":"code","source":["!nvcc -Xcompiler -fPIC -shared matrix_lib.cu -o libmatrix.so"],"metadata":{"id":"u5MWsGzAVi8c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ctypes\n","import numpy as np\n","import time\n","\n","# Load shared library\n","lib = ctypes.cdll.LoadLibrary(\"./libmatrix.so\")\n","\n","# Define argument types\n","lib.gpu_matrix_multiply.argtypes = [\n","np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n","np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n","np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n","ctypes.c_int\n","]\n","N = 1024\n","A = np.random.rand(N, N).astype(np.float32)\n","B = np.random.rand(N, N).astype(np.float32)\n","C = np.zeros((N, N), dtype=np.float32)\n","start = time.time()\n","lib.gpu_matrix_multiply(A.ravel(), B.ravel(), C.ravel(), N)\n","end = time.time()\n","print(f\"Python call to CUDA library completed in {end - start:.4f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VrFlYkxwVq3R","executionInfo":{"status":"ok","timestamp":1769884535059,"user_tz":480,"elapsed":148,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"343e55af-211c-45ec-e3a4-ca697352426e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python call to CUDA library completed in 0.1164 seconds\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","project_path = '/content/drive/MyDrive/Colab Notebooks/scripts'\n","os.makedirs(project_path, exist_ok=True)\n","os.chdir(project_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cMb60ftydmwK","executionInfo":{"status":"ok","timestamp":1769903582954,"user_tz":480,"elapsed":506,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"14589134-8161-4e20-9d09-ebf65c6cd378"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["os.path.exists(\"test_1.txt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEQhbATbf5r4","executionInfo":{"status":"ok","timestamp":1769903999615,"user_tz":480,"elapsed":6,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"8468dff6-0c39-4ef4-8018-5c383decddb0"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["%%writefile convolution_gpu.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <time.h>\n","#include <cuda_runtime.h>\n","\n","__global__ void convolutionGPU(unsigned int *input, unsigned int *output, float *kernel, int M, int N) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","    int offset = N / 2;\n","\n","    if (row < M && col < M) {\n","        float sum = 0.0f;\n","        for (int ki = 0; ki < N; ki++) {\n","            for (int kj = 0; kj < N; kj++) {\n","                int ii = row + ki - offset;\n","                int jj = col + kj - offset;\n","                if (ii >= 0 && ii < M && jj >= 0 && jj < M) {\n","                    sum += input[ii * M + jj] * kernel[ki * N + kj];\n","                }\n","            }\n","        }\n","        if (sum < 0.0f) sum = 0.0f;\n","        if (sum > 255.0f) sum = 255.0f;\n","        output[row * M + col] = (unsigned int)sum;\n","    }\n","}\n","\n","unsigned int* readMatrixManaged(const char *filename, int *M) {\n","    FILE *fp = fopen(filename, \"r\");\n","    if (!fp) return NULL;\n","    int cols;\n","    if (fscanf(fp, \"%d %d\", M, &cols) != 2) {\n","        fclose(fp);\n","        return NULL;\n","    }\n","    unsigned int *data;\n","    cudaMallocManaged(&data, *M * *M * sizeof(unsigned int));\n","    for (int i = 0; i < *M * *M; i++) {\n","        fscanf(fp, \"%u\", &data[i]);\n","    }\n","    fclose(fp);\n","    return data;\n","}\n","\n","void saveMatrix(const char *filename, unsigned int *data, int M) {\n","    FILE *fp = fopen(filename, \"w\");\n","    if (!fp) return;\n","    fprintf(fp, \"%d %d\\n\", M, M);\n","    for (int i = 0; i < M * M; i++) {\n","        fprintf(fp, \"%u \", data[i]);\n","        if ((i + 1) % M == 0) fprintf(fp, \"\\n\");\n","    }\n","    fclose(fp);\n","}\n","\n","float* generateFilterManaged(int N) {\n","    float *filter;\n","    cudaMallocManaged(&filter, N * N * sizeof(float));\n","    if (N == 3) {\n","        float laplacian[9] = {0, -1, 0, -1, 4, -1, 0, -1, 0};\n","        for(int i=0; i<9; i++) filter[i] = laplacian[i];\n","    } else {\n","        float val = 1.0f / (N * N);\n","        for (int i = 0; i < N * N; i++) {\n","            filter[i] = val;\n","        }\n","    }\n","    return filter;\n","}\n","\n","int main(int argc, char **argv) {\n","    const char *filenames[] = {\"test_1.txt\", \"test_2.txt\", \"test_3.txt\"};\n","    int filter_sizes[] = {3, 5, 7};\n","    int num_images = 3;\n","    int num_filters = 3;\n","\n","    for (int i = 0; i < num_images; i++) {\n","        const char *input_path = filenames[i];\n","\n","        int M;\n","        unsigned int *input = readMatrixManaged(input_path, &M);\n","        if (!input) {\n","            printf(\"Failed to read file: %s\\n\", input_path);\n","            continue;\n","        }\n","\n","        unsigned int *output;\n","        cudaMallocManaged(&output, M * M * sizeof(unsigned int));\n","\n","        for (int j = 0; j < num_filters; j++) {\n","            int N = filter_sizes[j];\n","            float *kernel = generateFilterManaged(N);\n","\n","            dim3 threadsPerBlock(16, 16);\n","            dim3 blocksPerGrid((M + threadsPerBlock.x - 1) / threadsPerBlock.x,\n","                               (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n","\n","            clock_t start = clock();\n","            convolutionGPU<<<blocksPerGrid, threadsPerBlock>>>(input, output, kernel, M, N);\n","            cudaDeviceSynchronize();\n","            clock_t end = clock();\n","\n","            double elapsed = (double)(end - start) / CLOCKS_PER_SEC;\n","            printf(\"Image: %s (MxM=%dx%d), Filter: %dx%d, Time: %f s\\n\",\n","                   filenames[i], M, M, N, N, elapsed);\n","\n","            char output_path[64];\n","            sprintf(output_path, \"result_%d_%dx%d.txt\", M, N, N);\n","            saveMatrix(output_path, output, M);\n","\n","            cudaFree(kernel);\n","        }\n","\n","        cudaFree(input);\n","        cudaFree(output);\n","    }\n","    return 0;\n","}"],"metadata":{"id":"WggEOetrfvtB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769904014624,"user_tz":480,"elapsed":12,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"d93a129a-e0e4-4781-e57d-27e51dccc4cf"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting convolution_gpu.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 convolution_gpu.cu -o convolution_gpu_run"],"metadata":{"id":"2IzIiBbedCEO","executionInfo":{"status":"ok","timestamp":1769904018345,"user_tz":480,"elapsed":1105,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["!./convolution_gpu_run"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AeQcrG80dJPU","executionInfo":{"status":"ok","timestamp":1769904025422,"user_tz":480,"elapsed":4321,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"7e017a9b-5cd1-4515-f69f-04014ef81548"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Image: test_1.txt (MxM=2048x2048), Filter: 3x3, Time: 0.008173 s\n","Image: test_1.txt (MxM=2048x2048), Filter: 5x5, Time: 0.006555 s\n","Image: test_1.txt (MxM=2048x2048), Filter: 7x7, Time: 0.006922 s\n","Image: test_2.txt (MxM=1024x1024), Filter: 3x3, Time: 0.004860 s\n","Image: test_2.txt (MxM=1024x1024), Filter: 5x5, Time: 0.003811 s\n","Image: test_2.txt (MxM=1024x1024), Filter: 7x7, Time: 0.001347 s\n","Image: test_3.txt (MxM=512x512), Filter: 3x3, Time: 0.000082 s\n","Image: test_3.txt (MxM=512x512), Filter: 5x5, Time: 0.000058 s\n","Image: test_3.txt (MxM=512x512), Filter: 7x7, Time: 0.000635 s\n"]}]},{"cell_type":"code","source":["%%writefile convolution_lib.cu\n","#include <stdio.h>\n","#include <cuda_runtime.h>\n","\n","__global__ void convolutionGPU(unsigned int *input, unsigned int *output, float *kernel, int M, int N) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","    int offset = N / 2;\n","\n","    if (row < M && col < M) {\n","        float sum = 0.0f;\n","        for (int ki = 0; ki < N; ki++) {\n","            for (int kj = 0; kj < N; kj++) {\n","                int ii = row + ki - offset;\n","                int jj = col + kj - offset;\n","                if (ii >= 0 && ii < M && jj >= 0 && jj < M) {\n","                    sum += input[ii * M + jj] * kernel[ki * N + kj];\n","                }\n","            }\n","        }\n","        if (sum < 0.0f) sum = 0.0f;\n","        if (sum > 255.0f) sum = 255.0f;\n","        output[row * M + col] = (unsigned int)sum;\n","    }\n","}\n","\n","extern \"C\" void gpu_convolution_wrapper(unsigned int *h_input, unsigned int *h_output, float *h_kernel, int M, int N) {\n","    unsigned int *d_input, *d_output;\n","    float *d_kernel;\n","    size_t img_size = M * M * sizeof(unsigned int);\n","    size_t kern_size = N * N * sizeof(float);\n","\n","    cudaMalloc((void**)&d_input, img_size);\n","    cudaMalloc((void**)&d_output, img_size);\n","    cudaMalloc((void**)&d_kernel, kern_size);\n","\n","    cudaMemcpy(d_input, h_input, img_size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_kernel, h_kernel, kern_size, cudaMemcpyHostToDevice);\n","\n","    dim3 threadsPerBlock(16, 16);\n","    dim3 blocksPerGrid((M + threadsPerBlock.x - 1) / threadsPerBlock.x,\n","                       (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n","\n","    convolutionGPU<<<blocksPerGrid, threadsPerBlock>>>(d_input, d_output, d_kernel, M, N);\n","    cudaDeviceSynchronize();\n","\n","    cudaMemcpy(h_output, d_output, img_size, cudaMemcpyDeviceToHost);\n","\n","    cudaFree(d_input);\n","    cudaFree(d_output);\n","    cudaFree(d_kernel);\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D7pvgbPLgMxr","executionInfo":{"status":"ok","timestamp":1769904475408,"user_tz":480,"elapsed":48,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"5f7cd974-38e9-4577-e3dd-5d63d9f1c2a4"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing convolution_lib.cu\n"]}]},{"cell_type":"code","source":["!nvcc -Xcompiler -fPIC -shared -o convolution_lib.so convolution_lib.cu"],"metadata":{"id":"YR1g-k5Uhxcf","executionInfo":{"status":"ok","timestamp":1769904483618,"user_tz":480,"elapsed":1207,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["import ctypes\n","import numpy as np\n","import os\n","import time\n","\n","def get_kernel(N):\n","    if N == 3:\n","        return np.array([0, -1, 0, -1, 4, -1, 0, -1, 0], dtype=np.float32)\n","    else:\n","        return np.full(N * N, 1.0 / (N * N), dtype=np.float32)\n","\n","lib = ctypes.CDLL('./convolution_lib.so')\n","lib.gpu_convolution_wrapper.argtypes = [\n","    np.ctypeslib.ndpointer(dtype=np.uint32, ndim=1, flags='C_CONTIGUOUS'),\n","    np.ctypeslib.ndpointer(dtype=np.uint32, ndim=1, flags='C_CONTIGUOUS'),\n","    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags='C_CONTIGUOUS'),\n","    ctypes.c_int,\n","    ctypes.c_int\n","]\n","\n","filenames = [\"test_1.txt\", \"test_2.txt\", \"test_3.txt\"]\n","filter_sizes = [3, 5, 7]\n","\n","for fname in filenames:\n","    if not os.path.exists(fname):\n","        print(f\"File not found: {fname}\")\n","        continue\n","\n","    with open(fname, 'r') as f:\n","        header = f.readline().split()\n","        M = int(header[0])\n","\n","    h_input = np.loadtxt(fname, skiprows=1, dtype=np.uint32).flatten()\n","    h_output = np.zeros_like(h_input)\n","\n","    for N in filter_sizes:\n","        h_kernel = get_kernel(N)\n","\n","        start_time = time.time()\n","        lib.gpu_convolution_wrapper(h_input, h_output, h_kernel, M, N)\n","        end_time = time.time()\n","\n","        print(f\"Image: {fname} (MxM={M}x{M}), Filter: {N}x{N}, Time: {end_time - start_time:.6f} s\")\n","\n","        out_name = f\"result_{M}_{N}x{N}.txt\"\n","        np.savetxt(out_name, h_output.reshape(M, M), fmt='%u', header=f\"{M} {M}\", comments='')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irN2RX9RhzVX","executionInfo":{"status":"ok","timestamp":1769904522991,"user_tz":480,"elapsed":4159,"user":{"displayName":"Dr Duke","userId":"13759096210497998176"}},"outputId":"cd18f1e4-c9e4-4908-bc55-30af5aac7c0e"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Image: test_1.txt (MxM=2048x2048), Filter: 3x3, Time: 0.166284 s\n","Image: test_1.txt (MxM=2048x2048), Filter: 5x5, Time: 0.011030 s\n","Image: test_1.txt (MxM=2048x2048), Filter: 7x7, Time: 0.012252 s\n","Image: test_2.txt (MxM=1024x1024), Filter: 3x3, Time: 0.003047 s\n","Image: test_2.txt (MxM=1024x1024), Filter: 5x5, Time: 0.004043 s\n","Image: test_2.txt (MxM=1024x1024), Filter: 7x7, Time: 0.004118 s\n","Image: test_3.txt (MxM=512x512), Filter: 3x3, Time: 0.001529 s\n","Image: test_3.txt (MxM=512x512), Filter: 5x5, Time: 0.001608 s\n","Image: test_3.txt (MxM=512x512), Filter: 7x7, Time: 0.001569 s\n"]}]}]}